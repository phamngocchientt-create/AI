import streamlit as st
from google import genai
from google.genai import types
import os

# ==================================================
# üëá M√É FILE C·ª¶A B·∫†N (T√¥i ƒë√£ ƒëi·ªÅn s·∫µn)
MY_FILE_NAME = "files/501jm98gmcjc"
# ==================================================

st.set_page_config(page_title="Gia s∆∞ H√≥a h·ªçc THCS", layout="wide")
st.title("üë®‚Äçüî¨ Gia s∆∞ H√≥a h·ªçc THCS")

# Sidebar hi·ªÉn th·ªã th√¥ng tin
with st.sidebar:
    st.success("‚úÖ K·∫øt n·ªëi th√†nh c√¥ng!")
    st.info(f"üìö T√†i li·ªáu: `{MY_FILE_NAME}`")
    # S·ª≠ d·ª•ng model ch√≠nh th·ª©c t·ª´ danh s√°ch c·ªßa b·∫°n
    st.info("ü§ñ Model: gemini-2.0-flash")

@st.cache_resource
def setup_chat_session():
    # L·∫•y API Key t·ª´ bi·∫øn m√¥i tr∆∞·ªùng
    api_key = os.getenv("GEMINI_API_KEY") 
    if not api_key:
        st.error("‚ö†Ô∏è L·ªñI: Ch∆∞a thi·∫øt l·∫≠p GEMINI_API_KEY.")
        return None, None
        
    client = genai.Client(api_key=api_key)
    
    # H∆∞·ªõng d·∫´n cho AI
    sys_instruct = (
        "B·∫°n l√† Gia s∆∞ H√≥a h·ªçc THCS (L·ªõp 8-9) th√¢n thi·ªán. "
        "Nhi·ªám v·ª•: Tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa h·ªçc sinh CH√çNH X√ÅC d·ª±a tr√™n t√†i li·ªáu ƒë√≠nh k√®m. "
        "N·∫øu t√†i li·ªáu kh√¥ng c√≥ th√¥ng tin, h√£y n√≥i r√µ r·∫±ng b·∫°n kh√¥ng t√¨m th·∫•y trong gi√°o tr√¨nh."
    )

    try:
        # üëá ƒê√É CH·ªåN MODEL T·ªêT NH·∫§T TRONG DANH S√ÅCH C·ª¶A B·∫†N
        chat = client.chats.create(
            model="gemini-2.0-flash", 
            config=types.GenerateContentConfig(
                system_instruction=sys_instruct,
                temperature=0.5 # Gi·ªØ c√¢u tr·∫£ l·ªùi ·ªïn ƒë·ªãnh
            ),
            history=[
                types.Content(
                    role="user",
                    parts=[
                        types.Part.from_uri(
                            file_uri=f"https://generativelanguage.googleapis.com/v1beta/{MY_FILE_NAME}",
                            mime_type="text/plain"),
                        types.Part.from_text(text="ƒê√¢y l√† gi√°o tr√¨nh H√≥a h·ªçc. H√£y h·ªçc thu·ªôc n√≥ ƒë·ªÉ d·∫°y h·ªçc sinh.")
                    ]
                ),
                types.Content(
                    role="model",
                    parts=[types.Part.from_text(text="ƒê√£ r√µ. T√¥i ƒë√£ ƒë·ªçc t√†i li·ªáu v√† s·∫µn s√†ng d·∫°y H√≥a h·ªçc.")]
                )
            ]
        )
        return client, chat
    except Exception as e:
        st.error(f"‚ùå L·ªói k·∫øt n·ªëi Gemini: {e}")
        return None, None

# Kh·ªüi t·∫°o
client, chat_session = setup_chat_session()

# Qu·∫£n l√Ω l·ªãch s·ª≠ chat
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "Ch√†o em! Th·∫ßy l√† Gia s∆∞ H√≥a h·ªçc. Em mu·ªën h·ªèi v·ªÅ b√†i n√†o?"}]

# Hi·ªÉn th·ªã tin nh·∫Øn
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# X·ª≠ l√Ω khi ng∆∞·ªùi d√πng nh·∫≠p c√¢u h·ªèi
if prompt := st.chat_input("Nh·∫≠p c√¢u h·ªèi H√≥a h·ªçc..."):
    if not client: st.stop()
    
    # Hi·ªán c√¢u h·ªèi
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # AI tr·∫£ l·ªùi
    with st.chat_message("assistant"):
        with st.spinner("Th·∫ßy ƒëang suy nghƒ©..."):
            try:
                response = chat_session.send_message(prompt)
                st.markdown(response.text)
                st.session_state.messages.append({"role": "assistant", "content": response.text})
            except Exception as e:
                st.error(f"C√≥ l·ªói x·∫£y ra: {e}")
